# 事件抽取



### - 事件抽取定义

[^参考自]: [A_Survey_of_Event_Extraction_From_Text.pdf](..\Reference_Paper\A_Survey_of_Event_Extraction_From_Text.pdf)

事件抽取：事件抽取是信息抽取研究中一项重要且具有挑战性的任务，在信息检索、智能问答和知识图谱构建等方面有着广泛的实际应用。事件抽取任务旨在将此类事件描述信息从非结构化纯文本中提取为结构化形式。例如关于事件的“5W1H”（who, when, where, what, why and how）

**分类：**

- 闭域事件提取（Closed-domain event extraction）：使用预定义的事件模式从文本中发现和提取特定类型的所需事件。事件模式包含多个事件类型及其相应的事件结构。![WJFZ202301002_348](D:\Typora\img\WJFZ202301002_348.jpg)

  - **Schema限定的事件抽取的子任务：**（CLOSED-DOMAIN EVENT EXTRACTION）

    > Schema限定的事件抽取的子任务是指在已经定义好的事件类型和角色的基础上，从文本中抽取出事件的相关信息，包括事件触发词、事件类型、事件论元和论元角色。

    - 触发词识别（Trigger identification）：触发词是事件抽取的核心单元，能够清晰地表达一个事件的发生， 触发词识别子任务是从文本中找到触发词。
    - 事件分类（Event classification）：判断每个句子是否包含事件，以及确定该句子所属的一种或几种事件类型。
    - 论元识别（Argument identification）：从文本中识别某个事件类型所包含的所有论元，论元的识别往往依赖于事件分类和触发词识别的结果。
    - 论元角色分类（Argument role classification）：对文本中识别的每个论元进行分类，角色类别是基于事件抽取schema中的定义。

  

- 开放域事件提取 （open-domain event extraction）：在没有预定义事件模式的情况下，开放域事件提取旨在从文本中检测事件，在大多数情况下，还通过提取的事件关键字对类似事件进行聚类。事件关键字是指那些主要描述事件的单词/短语，有时关键字还分为触发器和自变量。TDT公共评估程序旨在自动发现以前未报告的事件，或跟踪新闻文章中以前发现的事件的进展[15]。除了事件，TDT还将故事定义为描述特定事件的新闻文章片段，将主题定义为文章中的一组事件，但与现实世界中的某个主题密切相关。

  - 开放域事件提取子任务
    - 故事分割：从新闻文章中检测故事的边界
    - 第一个故事检测：检测新闻流中讨论新话题的故事。
    - 主题检测：根据故事讨论的主题对故事进行分组。 
    - 主题跟踪：检测讨论先前已知主题的故事。
    - 故事链接检测：决定一对故事是否讨论同一主题。 



**事件抽取术语：**

- 事件指称/提及（Event Mention）：描述了事件的短语或句子文本，包括事件触发词和元素

- 事件类型（Event Type）：发生事件的类别，描述事件的性质

- 事件触发词（Event Trigger）：触发词是表达事件发生的名词或动词，是决定事件类型核心的特征词

- 事件元素/论元（Event Argument）：事件主要属性，包括实体、非实体参与者、时间等要素

- 论元角色（Argument Role）：论元与其参与事件之间的关系

[^参考自]: [A Survey on Deep Learning Event Extraction: Approaches and Applications | IEEE Journals & Magazine | IEEE Xplore](https://ieeexplore.ieee.org/document/9927311)；



### - 事件抽取方法分类

[^以下分类参考自]: [A_Survey_of_Event_Extraction_From_Text.pdf](..\Reference_Paper\A_Survey_of_Event_Extraction_From_Text.pdf)；

- 基于模式匹配的事件抽取

  - 手动模式构建

  - 自动模式构建

- 基于传统机器学习的事件抽取方法

  -  基于管道的事件抽取范式

  -  基于联合的事件抽取范式

- 基于深度学习的事件抽取方法
  - CNN
  - RNN
  - GNN
  - Transformer




[^以下分类参考自]: [低资源场景事件抽取研究综述_刘涛.pdf](..\Reference_Paper\低资源场景事件抽取研究综述_刘涛.pdf)；

- 基于迁移学习的方法
  - 基于深度学习模型的迁移方法
    - CNN
    - RNN
    - GNN
    - Transformer
  - 基于预训练模型的方法
  - 基于机器阅读理解的方法
    - 基于监督学习的MRC方法
    - 基于无监督学习的MRC方法
  - 基于多任务学习的方法
- 基于提示学习的方法
  - 基于离散提示模板的方法
  - 基于连续提示模板的方法
- 基于无监督学习的方法
  - 基于表示学习及聚类的方法
  - 基于概率图模型的方法
  - 基于模式自动归纳与映射的方法
  - 基于对抗与对比训练的方法
- 基于弱监督学习的方法
  - 基于半监督学习的方法
  - 基于远程监督学习的方法
- 基于数据与辅助知识增强的方法
  - 基于多语言增强的方法
    - 基于机器翻译与映射的方法
    - 基于深度学习模型的方法
  - 基于多模态增强的方法
  - 基于辅助知识增强的方法
    - 基于框架语义与开放域知识增强的方法
    - 基于本体和规则增强的方法
- 基于元学习的方法










### - 深度学习抽取方法总结

[^参考自]: [基于深度学习的事件抽取模型总结 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/577131696)；[Deep Learning Schema_based Event Extraction_Literature Review and Current Trends.pdf](..\Reference_Paper\Deep Learning Schema_based Event Extraction_Literature Review and Current Trends.pdf)

事件抽取往往先将CNN、RNN、Transformer等模型作为编码器对文本编码，然后通过解码器判别事件类型、抽取事件论元的内容。许多研究提出不同的解码抽取方法，最早将事件抽取看做多分类问题，对事件类型和论元角色进行分类，但分类的方法依赖于实体识别预先抽取的事件元素，存在明显的误差累计问题。为此，基于序列标注的事件抽取方法被提出，在论元抽取时标注论元的起始位置，同时实现论元的识别与角色分类。为了学习事件类型与论元角色，以及论元间的依存关系，基于阅读理解的事件抽取方法被提出。最近，生成式信息抽取范式开始发展，基于生成的事件抽取方法被提出，能够统一建模不同场景、任务、schema下的抽取任务，生成预测不同的标签。



#### 2.1 Classification-based Methods（基于分类的事件抽取）

> - [Event Extraction via Dynamic Multi-Pooling Convolutional Neural Networks， ACL 2015](https://link.zhihu.com/?target=https%3A//aclanthology.org/P15-1017.pdf)
> - [Joint Event Extraction via Recurrent Neural Networks，ACL 2016](https://link.zhihu.com/?target=https%3A//aclanthology.org/N16-1034.pdf)

基于分类的事件抽取方法需要利用命名实体识别预先从文本中抽取出时间、地点、命名实体、以及非实体事件元素等构成候选事件论元集合  ，接下来的抽取主要分为两个个步骤：

- 事件类别分类：从句子中识别触发词trigger，并基于触发词进行事件分类，预测事件类型  ；
- 论元角色分类：判断候选论元中属于事件的论元，对论元进行角色分类，预测论元角色 



**分类方法缺点：**

- **不能解决overlapped事件和nested事件的抽取**
- **存在明显的误差累计问题：**事件论元识别和角色分类依赖于额外的命名实体识别模型的提取结果，即事件论元识别与论元分类是严重分离的，导致误差累计严重，性能较差；
- **分类方法泛化能力较差**：基于分类的方法在遇到新的事件类型或论元类型时只能重新训练，泛化能力差。

[^什么是overlapped事件和nested事件]: - 重叠事件：在句子“**Bob** was **arrested** by the police after he **robbed** a bank.”中，有两个事件，分别是“arrest”和“rob”，它们的触发词是“arrested”和“robbed”，它们的论元是“Bob”和“a bank”。这两个事件有一个共同的论元“Bob”，所以它们是重叠的。- 嵌套事件：在句子“**Alice** **announced** that she would **resign** from her position as CEO.”中，有两个事件，分别是“announce”和“resign”，它们的触发词是“announced”和“resign”，它们的论元是“Alice”和“her position as CEO”。这两个事件之间有一个包含关系，即“resign”事件是“announce”事件的一部分，所以它们是嵌套的。



#### 2.2 Sequence Labeling-based Methods（基于序列标注的抽取方法）

> - [Exploring Pre-trained Language Models for Event Extraction and Generation, ACL 2019](https://link.zhihu.com/?target=https%3A//aclanthology.org/P19-1522.pdf)
> - [Biomedical Event Extraction as Sequence Labeling，EMNLP 2020](https://link.zhihu.com/?target=https%3A//aclanthology.org/2020.emnlp-main.431.pdf)

基于序列标注的抽取方法其实是词级别的多分类问题，该方法不再依赖于额外的实体识别模型提取候选论元，而是将论元识别和角色分类统一至序列标注这一过程，首先模型仍然是识别句子中的触发词并进行事件分类，确定事件类型后，对句子进行词级别的序列标注，这一过程和命名实体识别是一样的，将论元角色类别和BIO标签组合分配给每一个词，从而获得事件的论元及其角色类别。



**序列标注方法缺点：**

- **不能解决overlapped事件和nested事件的抽取**
- **仍然存在误差累计：**实体类型到论元抽取过程存在事件类型的误差传递
- **泛化性差：**序列标注本质还是分类模型，训练好的模型无法处理新的事件类别和论元角色

#### 2.3 Machine Reading Comprehension-based Methods（基于阅读理解的方法）

> - [Event Extraction as Multi-turn Question Answering, ACL 2020](https://link.zhihu.com/?target=https%3A//aclanthology.org/2020.findings-emnlp.73.pdf)
> - [Event Extraction as Machine Reading Comprehension, ACL 2020](https://link.zhihu.com/?target=https%3A//aclanthology.org/2020.emnlp-main.128.pdf)
> - [Event Extraction by Answering (Almost) Natural Questions, ACL 2020](https://link.zhihu.com/?target=https%3A//aclanthology.org/2020.emnlp-main.49.pdf)

事件抽取可以看做多个子任务的顺序执行：trigger识别 -> trigger分类 -> 论元识别 -> 论元角色分类。基于阅读理解的方法将每个子任务转化为阅读理解问题，整个事件抽取过程就可以看做多轮问答任务的执行。每个子任务抽取阶段都有对应的文本模板，通过在问题模型中嵌入识别的trgger、不同的事件类别、论元角色类别等信息构造问句与输入句子拼接进行答案生成或者答案片段的抽取，最终迭代的完成事件抽取。



**阅读理解方法优点：**

- **可以解决flat事件、overlapped事件和nested事件的抽取**
- **可以学习事件类别和论元类别标签的关联关系**：事件类别会出现在论元角色分类的问句中，已抽取的论元也可出现在后续论元抽取的问句中，直接建模了事件类别与论元角色，以及事件论元之间的依赖关系。
- **泛化性强，模型可直接应用于新的事件类型和论元角色**：问句中可以为新的类别融入外部知识和信息。

**阅读理解方法缺点：**

- **推断计算效率低：**在进行事件分类和论元角色分类时，需要将每个事件类别和论元角色类别进行问题构造，并与句子拼接进行单独判断，计算复杂度增加。

#### 2.4 Generation-based Methods（基于生成的方法）

> - [TEXT2EVENT: Controllable Sequence-to-Structure Generation for End-to-end Event Extraction, ACL 2021](https://link.zhihu.com/?target=https%3A//aclanthology.org/2021.acl-long.217.pdf)
> - [DEGREE: A Data-Efficient Generation-Based Event Extraction Model ](https://link.zhihu.com/?target=https%3A//aclanthology.org/2022.naacl-main.138.pdf), 2021
> - [Unifified Structure Generation for Universal Information Extraction, ACL 2022](https://link.zhihu.com/?target=https%3A//aclanthology.org/2022.acl-long.395.pdf)

基于生成的方法是不同于分类、序列标注和阅读理解的事件抽取新范式，它不再将事件抽取分解为触发词提取、论元识别、论元分类等不同的子任务和预测标签，而是在sequence-to-structure架构中对整个事件提取过程统一建模，并且所有触发词、论元及其角色类别标签都作为自然语言词统一的生成，以端到端的方式从文本中提取事件。 如下图所示，基于sequence-to-structure生成的方法直接生成所有论元及其角色。 它通常采用BART、T5等encoder-decoder模型，这是一种将文本转换为结构化形式的简单方法。



**生成方法的优点：**

- **理想情况下可以解决flat事件、overlapped事件和nested事件的抽取**
- **端到端的统一建模：**不需要将事件抽取分解为多个子任务，避免了不同任务间的误差传播，也不需要人工设定不同任务组件间的信息共享和决策依赖关系，避免次优和不灵活的模型结构。

**生成方法的缺点：**

- **生成规范事件结构较困难：**生成模型生成的事件往往存在不准确、事件格式不规范、生成内容混乱不可控的问题，模型训练难度高，当前生成式抽取方法还未能完全超越抽取式抽取方法。

[^什么是flat事件]: 是指在同一句子或文档中只存在一个事件，并且该事件没有重叠或嵌套的关系。flat事件是最简单的事件类型，也是大多数传统的事件抽取方法所关注的对象。



### - 事件抽取的深度学习模型

[^参考自]: [A Survey on Deep Learning Event Extraction: Approaches and Applications | IEEE Journals & Magazine | IEEE Xplore](https://ieeexplore.ieee.org/document/9927311)

#### **1. 基于CNN的模型**

基于CNN的模型是一种利用卷积神经网络来抽取句子中的局部特征和基于事件触发词和论元的关键特征的方法。它可以在不使用复杂的自然语言处理工具的情况下自动学习词汇和句子级别的特征，但不能很好地处理非连续k-gram和事件之间的关联。

#### **2. 基于RNN的模型**

基于RNN的模型是一种利用循环神经网络来对序列信息进行建模的方法。它可以利用双向RNN来总结上下文信息，并用于识别事件触发词和论元角色。它也可以利用依赖关系图信息来增强信息流，但在捕捉非常长范围的依赖关系方面效率很低。

#### **3. 基于注意力的模型**

基于注意力的模型是一种利用注意力机制来对局部上下文进行建模的方法。它可以使用全局信息来关注重要特征信息，并通过控制句子每个部分的不同权重信息来提高事件抽取的性能和可解释性。它也可以使用层级注意力机制来进行信息的全局聚合，并利用事件触发词和论元角色之间的相互依赖性。

#### **4. 基于图卷积网络的模型**

基于图卷积网络的模型是一种利用图卷积网络来对文档级事件图进行建模的方法。它可以利用句法关系或事件-事件关系来构建文档级事件图，并使用基于图的注意力网络方法在图上传播时间信息，以提高事件检测和时间线构建的性能。它也可以利用实体提及或事件跨度来聚合卷积向量，以生成用于事件类型预测的单个向量表示。

#### **5. 基于Transformer的模型**

基于Transformer的模型是一种利用预训练语言模型来获取强大的上下文表示能力的方法。它可以利用BERT等预训练语言模型来提高事件抽取的准确性和鲁棒性，并通过生成对抗性网络或跨度更新等方法来增强事件抽取。它也可以利用ELMo等预训练语言模型来提高实体和事件抽取的性能，并通过生成对抗性模仿学习来帮助模型关注更难检测的事件。

**总结**：大多数传统的事件抽取方法都采用人工构建的方法进行特征表示，并使用分类模型对触发词进行分类和识别论元角色。近年来，深度学习在图像处理、语音识别和自然语言处理等方面表现出了突出的效果。为了解决传统方法的不足，系统地讨论了基于深度学习的事件抽取。在BERT模型出现之前，主流的方法是从文本中找到触发词，并根据触发词判断文本的事件类型。随着BERT引入事件抽取模型，基于全文的事件类型识别方法成为主流。这是因为BERT具有出色的上下文表示能力，在文本分类任务中表现良好，尤其是在只有少量数据的情况下。







